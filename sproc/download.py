# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/80_download.ipynb.

# %% auto 0
__all__ = ['file', 'yaml_to_dict', 'make_urls', 'from_date']

# %% ../nbs/80_download.ipynb 2
import pathlib
import urllib
import datetime

import urllib3
import pandas as pd
# import rich.progress
# from tqdm.autonotebook import tqdm
from tqdm import tqdm
import yaml

import sproc.structure

# %% ../nbs/80_download.ipynb 4
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# %% ../nbs/80_download.ipynb 6
def file(
    url: str, # URL for the file to be downloaded
    output_file: str | pathlib.Path | None, # Name of the local file to be saved; if `None` its content is returned
    timeout: float = 2. # How long to wait for a response
    ) -> None | bytes:

    pool_manager = urllib3.PoolManager(cert_reqs='CERT_NONE')

    try:
    
        # the request is made
        request = pool_manager.request('GET', url, timeout=timeout)

    except urllib3.exceptions.MaxRetryError:

        # print(f'can\'t download "{url}"')

        raise Exception(f'can\'t download "{url}"')
    
    # if no output file was given...
    if output_file is None:
    
        # ...the content is returned
        return request.data

    # in case a `str` was passed
    output_file = pathlib.Path(output_file)

    with output_file.open('wb') as f:

        f.write(request.data)

# %% ../nbs/80_download.ipynb 13
def yaml_to_dict(
    url: str, # URL for the file to be downloaded
    timeout: float = 2. # How long to wait for a response
    ) -> dict: # YAML data
    "Read YAML data from an URL"

    return yaml.safe_load(file(url, None, timeout))

# %% ../nbs/80_download.ipynb 17
def make_urls(
    base_url: str, # URL to the server including the hosting directory
    base_filename: str, # File name without neither date information nor extension
    from_date: datetime.datetime # The starting date
    ) -> list[tuple[str, str]]: # List of tuples (URL, file name)
    "Assemble URLs for files of a given kind that are to be downloaded"

    # a "hack" to get a date one month (never mind the day) after `from_date`
    next_month = from_date.replace(day=28) + datetime.timedelta(days=5)

    today = datetime.datetime.today()

    # print(f'{from_date=}')
    # print(f'{next_month=}')
    # print(f'{today=}')

    end_year = today.year
    end_month = today.month

    urls_filenames = []

    def append(filename: str):

        urls_filenames.append((urllib.parse.urljoin(base_url, filename), filename))

    # if a month after `from_date` is still the same year...
    if next_month.year == from_date.year:
    
        # ...loop through the remaining months
        for month in range(next_month.month, 12+1):

            filename = base_filename + str(next_month.year) + str(month).zfill(2) + '.zip'

            append(filename)

    # for the year of `from_date` until the *previous* year
    for year in range(from_date.year+1, today.year):
    # for year in range(next_month.year+1, today.year):

        # print(f'{year=}')

        filename = base_filename + str(year) + '.zip'

        append(filename)
    
    for month in range(1, today.month):
        
        filename = base_filename + str(today.year) + str(month).zfill(2) + '.zip'

        append(filename)

    return urls_filenames

# %% ../nbs/80_download.ipynb 23
def from_date(
    kind: str, # One of 'outsiders', 'insiders', or 'minors'
    date: datetime.datetime, # The starting date
    output_directory: str | pathlib.Path = pathlib.Path.cwd() # Output directory, defaults is the current one
    ) -> list[pathlib.Path]: # File name of every downloaded file
    "Downloads all the files of a given kind from a certain moment in time"

    # in case a `str` was passed
    output_directory = pathlib.Path(output_directory)

    # `kind` should be one of the pre-set types
    assert kind in sproc.structure.tables

    info = sproc.structure.tables[kind]

    urls_filenames = make_urls(**info, from_date=date)

    every_output_file = []

    # in order to avoid showing a useless progress bar
    if not urls_filenames:

        return every_output_file

    for url, filename in tqdm(urls_filenames, desc='Downloading raw data'):
    # for url, filename in rich.progress.track(urls_filenames, description='Downloading raw data'):

        output_file = output_directory / filename

        # file is annotated *regardless* of whether download was needed or it was already there
        every_output_file.append(output_file)

        if output_file.exists():

            # print(f'"{output_file.name}" already exists')
            tqdm.write(f'"{output_file.name}" already exists')
            
            continue

        tqdm.write(f'downloading "{output_file.name}"...')

        # file is actually downloaded
        file(url, output_file)

    return every_output_file
