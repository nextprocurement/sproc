# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/30_hierarchical.ipynb.

# %% auto 0
__all__ = ['flat_series_to_multiindexed_series', 'flat_df_to_multiindexed_df', 'pad_col_levels', 'columns_containing',
           'is_column_multiindexed', 'data_scheme_ok', 'flatten_columns_names']

# %% ../nbs/30_hierarchical.ipynb 2
import pathlib
import itertools

import pandas as pd
import numpy as np
from lxml import etree
import yaml

# import sproc.xml
import sproc.structure

# %% ../nbs/30_hierarchical.ipynb 26
def flat_series_to_multiindexed_series(
    s: pd.Series # Flat series
) -> pd.Series: # Multi-indexed series
    "Returns a multi-indexed version of the input"
    
    index_paths = []
    values = []
    
    for i, v in s.items():
        index_paths.append(tuple(i.split(sproc.structure.nested_tags_separator)))
        values.append(v)
        
    return pd.Series(values, index=pd.MultiIndex.from_tuples(index_paths))

# %% ../nbs/30_hierarchical.ipynb 36
def flat_df_to_multiindexed_df(
    input_df: pd.DataFrame # Input `DataFrame`
) -> pd.DataFrame: # A column-hierarchical version of the input `DataFrame`
    "Reads and parses an XML file into a `DataFrame`"
    
    # every field becomes a `tuple`
    fields = [tuple(c.split(sproc.structure.nested_tags_separator)) for c in input_df.columns]
    
    # the number of levels in the multindex for the columns
    n_levels = len(max(fields, key=len))
    
    # every tuple is padded with empty string until it has `n_levels`
    fields = [e + ('',)*(n_levels-len(e)) for e in fields]

    index_hierarchical = pd.MultiIndex.from_tuples(fields)

    # an empty `pd.DataFrame`
    res = pd.DataFrame(None, columns=index_hierarchical)

    # every column in the *output* `pd.DataFrame`...
    for c in res.columns:

        # ...is filled in looking up the data in the input `pd.DataFrame` by means of the appropriate "merged" column name
        res[c] = input_df[sproc.structure.assemble_name(c)]
    
    return res

# %% ../nbs/30_hierarchical.ipynb 49
def pad_col_levels(
    df: pd.DataFrame, # Input
    levels: tuple | list, # Individual names to assemble and pad
    denan: bool = False # If `True`, skip `pd.NA`s
    ) -> tuple: # Multiindex column name
    "Builds a multiindex-amenable column name from a sequence of levels."
    
    # if "de-NaN" was requested...
    if denan:
        levels = [e for e in levels if pd.notna(e)]
    
    return tuple(list(levels) + [''] * (df.columns.nlevels - len(levels)))

# %% ../nbs/30_hierarchical.ipynb 57
def columns_containing(
    df: pd.DataFrame, # Input
    substring: str # Substring to be searched
    ):
    "Return the columns whose name contain a given substring"
    
    is_contained = [list(filter(lambda e: (type(e) != float) and (substring in e), c)) != [] for c in df.columns]
    
    return df.columns[is_contained]

# %% ../nbs/30_hierarchical.ipynb 60
def is_column_multiindexed(
    df: pd.DataFrame # Input
    ) -> bool: # Assessment
    "Returns `True` if the given `pd.DataFrame` is column-multiindex."

    return type(df.columns) == pd.MultiIndex

# %% ../nbs/30_hierarchical.ipynb 80
def data_scheme_ok(
    data_scheme: dict # Data scheme: every `key` a name, every `value` a *path*
    ) -> bool: # `True` if the data scheme is fine
    "Checks whether a data scheme is correct"
    
    lengths = []
    
    for l in data_scheme.values():
        
        lengths.append(len(l))
        
        # if not every element is a `str` or `nan`...
        if not np.all([(type(e) == str) or np.isnan(e) for e in l]):
            
            return False
        
    return True
    # return np.unique(lengths).shape[0] == 1 # <-------------------------- TODO: required?

# %% ../nbs/30_hierarchical.ipynb 90
def flatten_columns_names(
    df: pd.DataFrame, # Input
    data_scheme: dict # Every key is a flattened name, and every value a list with the different levels of the multi-index
    , inplace: bool = False # If `True` the input DataFrame is modified
    ) -> None | pd.DataFrame: # Flat DataFrame
    
    assert data_scheme_ok(data_scheme), f'data scheme is not OK'
    
    # the inverse of the above mapping (turning nan's into empty strings, and concatenating all the levels together)
    inv_data_scheme = {''.join([e if pd.notna(e) else '' for e in v]): k for k, v in data_scheme.items()}
    
    new_names = []
    
    for c in df.columns:
        
        stitched_c = ''.join(c)
        
        # if the column is found in the inverse mapping...
        if stitched_c in inv_data_scheme:
            
            # ...the given name is used
            new_names.append(inv_data_scheme[stitched_c])
            
        # if the columns is NOT found in the inverse mapping...
        else:
            
            # ...the new name is obtained by contatenating the individual components
            new_names.append(sproc.structure.nested_tags_separator.join([e for e in c if e != '']))
    
    if inplace:
        
       res = df
    
    else:
        
        res = df.copy()
    
    res.columns = new_names
    
    return res
